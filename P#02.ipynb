{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#******************************************************************************\n",
    "#QUESTION #02: PREDICTING INCOME \n",
    "#This study focuses on the US Adult Census dataset; a repository of 32,561 \n",
    "#entires carefully extracted from the 1994 US Census database. We would like to \n",
    "#determine if an individual has a salary greater than or less than $50,000 \n",
    "#annually based on the variables provided.\n",
    "#******************************************************************************\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "\n",
    "adult = pd.read_csv(\"http://www.webpages.uidaho.edu/~stevel/Datasets/adult.csv\")\n",
    "adult\n",
    "df= pd.DataFrame(adult)\n",
    "#adult.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA CLEAN UP\n",
    "\n",
    "#MAKING THE RESPONSE VARIABLE \"SALARY\" NUMERICAL BY MAKING LIST, TURNING \n",
    "#LIST INTO ARRAY AND BY ADDING NEW COLUMN TO END OF THE DATA FRAME WITH LOOP\n",
    " \n",
    "#SAVING THE STRING \n",
    "a = adult.salary[7]\n",
    "#MAKING INDEX\n",
    "i = 0\n",
    "terminate = 32561\n",
    "#DECLARING LIST\n",
    "lis = []\n",
    "while(i < terminate):\n",
    "    st = adult.salary[i]\n",
    "    if(st == a):\n",
    "        v = 1\n",
    "    else:\n",
    "        v = 0\n",
    "    #APPEND\n",
    "    lis.append(v)\n",
    "    #INCREMENT INDEX\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONVERTING LIS TO ARRAY\n",
    "a_ray = np.asarray(lis)\n",
    "#MAKING ARRAY INTO PANDAS DATA FRAME\n",
    "t = pd.DataFrame(a_ray)\n",
    "#NAMING NEW SALARY\n",
    "t.columns = ['salary_binary']\n",
    "#COMBINE DATA FRAMES ADDING NEW COLUMN TO END\n",
    "adultDF2 = pd.concat([adult,t], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploritory Data Analysis (EDA)\n",
    "\n",
    "#HEAT MAPS\n",
    "#Heat maps display numeric tabular data where the cells are colored depending \n",
    "#upon the contained value\n",
    "hmap = adult.corr()\n",
    "sns.heatmap(hmap, vmax=.8,annot=True,cmap=\"cool\", square=True);\n",
    "#The heat map for this example suggests that there are no variables that are \n",
    "#strongly correlated. Therefore, keep all variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COUNTPLOT\n",
    "sns.countplot(x='salary_binary', data=adultDF2);\n",
    "#The countplot for this example suggests that the number of people who make\n",
    "#less that 50k over twice as much as the number of people who make more than \n",
    "#50k\n",
    "#sns.countplot(x='education_num', data=adultDF2);\n",
    "#sns.countplot(x='hours_per_week', data=adultDF2); \n",
    "#sns.countplot(x='race', data=adultDF2);\n",
    "#sns.countplot(x='sex', data=adultDF2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='education_num', y='hours_per_week', hue='salary_binary', data=adultDF2, fit_reg=False, scatter_kws={'alpha':0.5});\n",
    "#It is important to note that it looks like those who make more than 50k are \n",
    "#more educated and work more hours per week "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=adultDF2[['education_num','age','hours_per_week', 'fnlwgt', 'capital_gain', 'capital_loss']].values\n",
    "y= adultDF2[['salary_binary']].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X ,y, test_size=0.2, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECISION TREE\n",
    "#Decision trees is a supervised machine learning algorithm that can be applied \n",
    "#to both classification and regression purposes\n",
    "#Pros:\n",
    "#(#01)Trees can easily handle qualitative predictors without the need to \n",
    "#create dummy variables.\n",
    "#(#02)Trees can be displayed graphically, and are easily interpreted even \n",
    "#by a non-expert.\n",
    "#Cons: \n",
    "#(#01)Unfortunately, trees generally do not have the same level of predictive \n",
    "#accuracy as some of the other regression and classiﬁcation approaches seen\n",
    "#(#02)Additionally, trees can be very non-robust. In other words, a small \n",
    "#change in the data can cause a large change in the ﬁnal estimated tree.\n",
    "DTC= tree.DecisionTreeClassifier()\n",
    "DTC.fit(X_train, y_train)\n",
    "TP1=DTC.predict(X_test)\n",
    "#Check to see if response is binary NOT probabilistic\n",
    "TP1 \n",
    "report01 = classification_report(y_test, TP1)\n",
    "print(confusion_matrix(y_test, TP1))\n",
    "print(report01)\n",
    "print(\"Accuracy of this test: \")\n",
    "print(accuracy_score(y_test, TP1))\n",
    "#AUROC SCORE\n",
    "print(\"Area under the ROC curve: \")\n",
    "roc_auc_score(y_test, TP1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria-Eugenia\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "#******************************************************************************\n",
    "#SUPPORT VECTOR MACHINE\n",
    "#SVM is a supervised machine learning algorithm that can be applied to\n",
    "#both classification and regression purposes\n",
    "#The goal is to choose a hyperplane with the greatest possible margin between\n",
    "#the hyperplane and any point within the training set, giving a greater chance \n",
    "#of new data being classified correctly.\n",
    "#Pros:\n",
    "#(#01)Find optimal seperation in hyperplane\n",
    "#(#02)Can deal with very high dimentional data\n",
    "#Cons:\n",
    "#(#01)Require lots of memory and CPU time \n",
    "#(#02)Need to select good kernel function \n",
    "svc = svm.SVC(kernel='linear')\n",
    "svc.fit(X_train, y_train)\n",
    "TP2=svc.predict(X_test)\n",
    "#TP2 Check to see if response is binary NOT probabilistic \n",
    "report02 = classification_report(y_test, TP2)\n",
    "print(confusion_matrix(y_test, TP2))\n",
    "print(report02)\n",
    "print(\"Accuracy of this test: \")\n",
    "print(accuracy_score(y_test, TP2))\n",
    "#AUROC\n",
    "print(\"Area under the ROC curve: \")\n",
    "roc_auc_score(y_test, TP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting\n",
    "#Gradient boosting is a machine learning technique for regression and \n",
    "#classification problems, which produces a prediction model in the form of an \n",
    "#ensemble of weak prediction models, typically decision trees. It builds the \n",
    "#model in a stage-wise fashion like other boosting methods do, and it \n",
    "#generalizes them by allowing optimization of an arbitrary differentiable \n",
    "#loss function.\n",
    "#PROS:\n",
    "#(#01) High functioning \n",
    "#CONS:\n",
    "#(#01) A small change in feature/training set can create a radical changes in \n",
    "#model\n",
    "#(#02) Not easy to understand predictions\n",
    "GB = GradientBoostingClassifier(random_state = 0) \n",
    "GB.fit(X_train, y_train)\n",
    "TP3= GB.predict(X_test)\n",
    "#TP3 Check to see if response is binary NOT probabilistic \n",
    "report03 = classification_report(y_test, TP3)\n",
    "print(confusion_matrix(y_test, TP3))\n",
    "print(report03)\n",
    "print(\"Accuracy of this test: \")\n",
    "print(accuracy_score(y_test, TP3))\n",
    "#AUROC\n",
    "print(\"Area under the ROC curve: \")\n",
    "roc_auc_score(y_test, TP3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
